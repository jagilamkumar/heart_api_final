{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iat7DXhiGm06"
      },
      "outputs": [],
      "source": [
        "!pip install pymongo pandas scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# Load raw CSV\n",
        "df_raw = pd.read_csv('/content/heart_disease_uci.csv')\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = MongoClient(\"mongodb+srv://mluser:Kumar321@cluster0.u30ux5m.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
        "db = client['healthcare']\n",
        "bronze_collection = db['heart_disease_bronze']\n",
        "\n",
        "# Insert raw data as JSON\n",
        "bronze_collection.insert_many(df_raw.to_dict(orient='records'))\n"
      ],
      "metadata": {
        "id": "N9mP8pbOG36q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Step 1: Connect to MongoDB and fetch Bronze layer data\n",
        "client = MongoClient(\"mongodb+srv://mluser:Kumar321@cluster0.u30ux5m.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
        "db = client['healthcare']\n",
        "bronze_collection = db['heart_disease_bronze']\n",
        "data = list(bronze_collection.find({}, {'_id': 0}))  # exclude _id\n",
        "df_silver = pd.DataFrame(data)\n",
        "\n",
        "# Step 2: Handle missing values\n",
        "numerical_cols = df_silver.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_cols = df_silver.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "df_silver[numerical_cols] = df_silver[numerical_cols].fillna(df_silver[numerical_cols].mean())\n",
        "\n",
        "for col in categorical_cols:\n",
        "    df_silver[col] = df_silver[col].fillna(df_silver[col].mode()[0])\n",
        "\n",
        "# Step 3: Encode categorical features\n",
        "label_enc_cols = ['sex', 'cp', 'thal', 'slope', 'restecg']  # adjust based on dataset\n",
        "\n",
        "for col in label_enc_cols:\n",
        "    if col in df_silver.columns:\n",
        "        le = LabelEncoder()\n",
        "        df_silver[col] = le.fit_transform(df_silver[col])\n",
        "\n",
        "# Step 4: Store preprocessed data into Silver layer\n",
        "silver_collection = db['heart_disease_silver']\n",
        "silver_collection.insert_many(df_silver.to_dict(orient='records'))\n",
        "\n",
        "print(\"Silver layer preprocessing complete and data inserted into MongoDB.\")\n"
      ],
      "metadata": {
        "id": "iOI_sgYXL1OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "\n",
        "# Step 1: Connect to MongoDB and load Silver data\n",
        "client = MongoClient(\"mongodb+srv://mluser:Kumar321@cluster0.u30ux5m.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
        "db = client['healthcare']\n",
        "silver_collection = db['heart_disease_silver']\n",
        "data = list(silver_collection.find({}, {'_id': 0}))\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 2: Drop unwanted columns only (keep 'sex')\n",
        "df.drop(columns=[col for col in ['id', 'dataset'] if col in df.columns], inplace=True)\n",
        "\n",
        "# Step 3: Rename 'num' to 'target' if present\n",
        "if 'num' in df.columns:\n",
        "    df.rename(columns={'num': 'target'}, inplace=True)\n",
        "\n",
        "# Step 4: Normalize numerical features\n",
        "numerical_cols = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak']\n",
        "scaler = MinMaxScaler()\n",
        "for col in numerical_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = scaler.fit_transform(df[[col]])\n",
        "\n",
        "# Step 5: Encode categorical features\n",
        "label_enc = LabelEncoder()\n",
        "for col in ['fbs', 'exang']:\n",
        "    if col in df.columns:\n",
        "        df[col] = label_enc.fit_transform(df[col])\n",
        "\n",
        "# Step 6: Save to Gold collection\n",
        "gold_collection = db['heart_disease_gold']\n",
        "gold_collection.delete_many({})  # Optional: clear existing\n",
        "gold_collection.insert_many(df.to_dict(orient='records'))\n",
        "\n",
        "# Step 7: Preview Gold layer\n",
        "df_gold = pd.DataFrame(list(gold_collection.find({}, {'_id': 0})))\n",
        "print(\"âœ… Gold layer sample:\")\n",
        "display(df_gold.head())\n"
      ],
      "metadata": {
        "id": "4ylXYW1jNA-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score\n",
        ")\n",
        "\n",
        "# Connect to MongoDB and fetch gold layer data\n",
        "client = MongoClient(\"mongodb+srv://mluser:Kumar321@cluster0.u30ux5m.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
        "db = client['healthcare']\n",
        "gold_data = list(db['heart_disease_gold'].find({}, {'_id': 0}))\n",
        "df = pd.DataFrame(gold_data)\n",
        "\n",
        "# Features and target\n",
        "X = df.drop(columns=['target'])\n",
        "y = df['target']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'SVM': SVC(probability=True, random_state=42),\n",
        "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "}\n",
        "\n",
        "# Evaluation\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Predict probabilities (needed for ROC AUC)\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        y_proba = model.predict_proba(X_test)\n",
        "    else:\n",
        "        y_proba = None\n",
        "\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'Recall': recall_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'F1 Score': f1_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'ROC-AUC': roc_auc_score(y_test, y_proba, multi_class='ovr') if y_proba is not None else 'N/A'\n",
        "    }\n",
        "\n",
        "# Print results\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"\\nðŸ“Š {model_name}\")\n",
        "    for metric, value in metrics.items():\n",
        "        if isinstance(value, float):\n",
        "            print(f\"{metric}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"{metric}: {value}\")\n"
      ],
      "metadata": {
        "id": "Z2b1nEph213Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show xgboost\n"
      ],
      "metadata": {
        "id": "5GO5eSAmLASE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Re-train XGBoost on the full dataset (optional but recommended)\n",
        "final_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "final_model.fit(X, y)  # X and y already defined from the gold layer\n",
        "\n",
        "# Save model as pkl\n",
        "joblib.dump(final_model, 'xgboost_heart_disease_model.pkl')\n",
        "\n",
        "print(\"âœ… Model saved as 'xgboost_heart_disease_model.pkl'\")\n"
      ],
      "metadata": {
        "id": "Q8KTqZZG3ttX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load your XGBoost model\n",
        "with open(\"xgboost_heart_disease_model.pkl\", \"rb\") as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "# Show feature names\n",
        "print(model.feature_names_in_)\n"
      ],
      "metadata": {
        "id": "mU6CTfH6GQ0q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}